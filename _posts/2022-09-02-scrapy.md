---
layout: post
title: "Scrapy2.6 Document"
author: "Fanqiang Meng"
categories: journal
tags: [documentation,sample,pic]

---
Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.

## 安装Scrapy
```bash
pip install scrapy
```
> 为了避免与系统包冲突，文档中是建议在虚拟环境中安装

## 创建Scrapy项目
```bash
scrapy startproject <name> [project_dir]
```
输入命令创建爬虫项目
**Scrapy项目目录**

```bash
Lagrange/
├── _data                      # Data files
|  └── settings.yml            # Theme settings and custom text
├── _includes                  # Theme includes
├── _layouts                   # Theme layouts (see below for details)
├── _posts                     # Where all your posts will go
├── assets                     # Style sheets and images are found here
|  ├── css                     # Style sheets go here
|  |  └── main.css             # Main CSS file
|  |  └── syntax.css           # Style sheet for code syntax highlighting
|  └── img                     # Images go here
├── menu                       # Menu pages
├── _config.yml                # Site build settings
├── Gemfile                    # Ruby Gemfile for managing Jekyll plugins
├── index.md                   # Home page
├── LICENSE.md                 # License for this theme
├── README.md                  # Includes all of the documentation for this theme
└── rss-feed.xml               # Generates RSS 2.0 file which Jekyll points to
```

## 创建爬虫
```bash
scrapy genspider [-t template] <name> <domain or URL>

# spiders如果從項目內部調用，則在當前文件夾或當前項目的文件夾中創建一個新蜘蛛。
# <name>參數設置為spider的，namewhile用於生成spider和spider的屬性。
# <domain or URL>allowed_domainsstart_urls
```

## 运行爬虫
```bash
scrapy crawl <spider>
```
