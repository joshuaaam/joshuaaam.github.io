<!--
 * @Author: g05047
 * @Date: 2022-09-02 17:24:59
 * @LastEditors: g05047
 * @LastEditTime: 2022-09-02 23:12:38
 * @Description: file content
-->
---
layout: post
title: "Scrapy2.6 Document"
author: "Fanqiang Meng"
categories: journal
tags: [documentation,sample,pic]

---
Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.

## 安装Scrapy
```bash
pip install scrapy
```
> 为了避免与系统包冲突，文档中是建议在虚拟环境中安装

## 创建Scrapy项目
```bash
scrapy startproject <name> [project_dir]
```
输入命令创建爬虫项目
**Scrapy项目目录**

```bash

tutorial
├── scrapy.cfg                  # deploy configuration file
└── tutorial                    # project's Python module, you'll import your code from here
| ├── __init__.py               
| ├── items.py                  # project items definition file
| ├── middlewares.py            # project middlewares file
| ├── pipelines.py              # project pipelines file
| ├── settings.py               # project settings file
| └── spiders                   # a directory where you'll later put your spidersdeploy configuration file
| | └── __init__.py            

```


## 创建爬虫
```bash
scrapy genspider [-t template] <name> <domain or URL>

# spiders如果從項目內部調用，則在當前文件夾或當前項目的文件夾中創建一個新蜘蛛。
# <name>參數設置為spider的，namewhile用於生成spider和spider的屬性。
# <domain or URL>allowed_domainsstart_url
```

## 运行爬虫
```bash
scrapy crawl <spider>
```
